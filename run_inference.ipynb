{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9SWC79FlK5LT",
      "metadata": {
        "id": "9SWC79FlK5LT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append(r'C:\\Users\\luchi\\.0_things\\1_College\\class\\5.1_CAE')\n",
        "import ml4floods\n",
        "import albumentations\n",
        "print(ml4floods.__version__)\n",
        "print(albumentations.__version__)\n",
        "# import importlib\n",
        "# importlib.reload(ml4floods)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e6a65f5",
      "metadata": {
        "id": "2e6a65f5"
      },
      "source": [
        "Step 1: Get config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cba6e049",
      "metadata": {
        "id": "cba6e049"
      },
      "outputs": [],
      "source": [
        "from ml4floods.models.config_setup import get_default_config\n",
        "\n",
        "folder_name_model_weights =\"/content/drive/MyDrive/Colab Notebooks/NTU_notebooks/CAE/models/training_demo\"\n",
        "\n",
        "config_fp = os.path.join(folder_name_model_weights, \"config.json\")\n",
        "\n",
        "config = get_default_config(config_fp)\n",
        "\n",
        "# The max_tile_size param controls the max size of patches that are fed to the NN. If you're in a memory contrained environment set this value to 128\n",
        "config[\"model_params\"][\"max_tile_size\"] = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39100d53",
      "metadata": {
        "id": "39100d53"
      },
      "source": [
        "Step 2: Load pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8645cd1",
      "metadata": {
        "id": "f8645cd1"
      },
      "outputs": [],
      "source": [
        "from ml4floods.models.model_setup import get_model\n",
        "experiment_name = 'training_demo'\n",
        "model_folder = os.path.dirname(folder_name_model_weights)\n",
        "if model_folder == \"\":\n",
        "    model_folder = \".\"\n",
        "\n",
        "config[\"model_params\"]['model_folder'] = model_folder\n",
        "config[\"model_params\"]['test'] = True\n",
        "model = get_model(config.model_params, experiment_name)\n",
        "\n",
        "model.eval()\n",
        "model.to(\"cuda\") # comment this line if your machine does not have GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c45cd2e",
      "metadata": {
        "id": "0c45cd2e"
      },
      "outputs": [],
      "source": [
        "from ml4floods.models.model_setup import get_model_inference_function\n",
        "\n",
        "inference_function = get_model_inference_function(model, config,apply_normalization=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7df1ac37",
      "metadata": {
        "id": "7df1ac37"
      },
      "source": [
        "Step 3: Run Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "740a5f6a",
      "metadata": {
        "id": "740a5f6a"
      },
      "outputs": [],
      "source": [
        "from ml4floods.models.model_setup import get_channel_configuration_bands\n",
        "from ml4floods.visualization import plot_utils\n",
        "from ml4floods.data.worldfloods import dataset\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "channel_configuration = config.model_params.hyperparameters.channel_configuration\n",
        "\n",
        "dataset_folder = \"/content/drive/MyDrive/Colab Notebooks/NTU_notebooks/CAE/worldfloods_v1_0_sample\"\n",
        "event_id = \"RS2_20161008_Water_Extent_Corail_Pestel.tif\"\n",
        "tiff_s2 = os.path.join(dataset_folder, \"val\", \"S2\", event_id)\n",
        "tiff_gt = os.path.join(dataset_folder, \"val\", \"gt\", event_id)\n",
        "tiff_permanentwaterjrc = os.path.join(dataset_folder, \"val\", \"PERMANENTWATERJRC\", event_id)\n",
        "window = None\n",
        "channels = get_channel_configuration_bands(channel_configuration)\n",
        "\n",
        "# Read inputs\n",
        "torch_inputs, transform = dataset.load_input(tiff_s2, window=window, channels=channels)\n",
        "\n",
        "# Make predictions\n",
        "outputs = inference_function(torch_inputs.unsqueeze(0))[1] # (num_classes, h, w)\n",
        "prediction = torch.argmax(outputs, dim=0).long() # (h, w)\n",
        "\n",
        "# Mask invalid pixels\n",
        "mask_invalid = torch.all(torch_inputs == 0, dim=0)\n",
        "prediction+=1\n",
        "prediction[mask_invalid] = 0\n",
        "\n",
        "# Load GT and permanent water for plotting\n",
        "torch_targets, _ = dataset.load_input(tiff_gt, window=window, channels=[0])\n",
        "torch_permanent_water, _ = dataset.load_input(tiff_permanentwaterjrc, window=window, channels=[0])\n",
        "\n",
        "\n",
        "# Plot\n",
        "fig, axs = plt.subplots(2,2, figsize=(16,16))\n",
        "plot_utils.plot_rgb_image(torch_inputs, transform=transform, ax=axs[0,0])\n",
        "axs[0,0].set_title(\"RGB Composite\")\n",
        "plot_utils.plot_swirnirred_image(torch_inputs, transform=transform, ax=axs[0,1])\n",
        "axs[0,1].set_title(\"SWIR1,NIR,R Composite\")\n",
        "plot_utils.plot_gt_v1_with_permanent(torch_targets, torch_permanent_water, window=window, transform=transform, ax=axs[1,0])\n",
        "axs[1,0].set_title(\"Ground Truth with JRC Permanent\")\n",
        "plot_utils.plot_gt_v1(prediction.unsqueeze(0),transform=transform, ax=axs[1,1])\n",
        "axs[1,1].set_title(\"Model prediction\")\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34bce117",
      "metadata": {
        "id": "34bce117"
      },
      "source": [
        "Step 4: Vectorise the water masks and plot them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e30dd3a8",
      "metadata": {
        "id": "e30dd3a8"
      },
      "outputs": [],
      "source": [
        "from ml4floods.models import postprocess\n",
        "from ml4floods.visualization import plot_utils\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "\n",
        "prob_water_mask = outputs[1].cpu().numpy()\n",
        "binary_water_mask = prob_water_mask>.5\n",
        "\n",
        "geoms_polygons = postprocess.get_water_polygons(binary_water_mask, transform=transform)\n",
        "geoms_polygons.to_file(\"flood.geojson\", driver='GeoJSON') # 存檔(新加的)\n",
        "\n",
        "data_out = gpd.GeoDataFrame({\"geometry\": geoms_polygons, \"id\": np.arange(len(geoms_polygons))})\n",
        "fig, ax = plt.subplots(1,1, figsize=(12, 12))\n",
        "data_out.plot(\"id\",legend=True,categorical=True,ax=ax,facecolor=\"None\",edgecolor=None,linewidth=3)\n",
        "plot_utils.plot_rgb_image(torch_inputs, transform=transform, ax=ax, alpha=.6,\n",
        "                             channel_configuration=channel_configuration)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
